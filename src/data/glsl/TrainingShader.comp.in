#version 450

/**
 * *TEMPLATE* GLSL training compute shader for Vulkan, by Dams 
 * Damien Balima (c) CC-BY-NC-SA-4.0 2024
 * Do not edit
 */
 
// One workgroup thread per neuron, one local thread per workgroup
layout (local_size_x = 1) in;

// Enum mapping, do not change
const int ELU = 0;
const int LReLU = 1;
const int PReLU = 2;
const int ReLU = 3;
const int Sigmoid = 4;
const int Tanh = 5;


vec4 derivativeFunction(vec4 value){
    bvec4 mask;
    switch (params.activationFunction) {
        case ELU:          
            mask = greaterThanEqual(value, vec4(0.0));
            value = mix(vec4(1.0), params.activationAlpha * exp(value), mask);       
        break;
        case LReLU:    
            value = clamp(value, 0.01, 1.0);         
        break;
        case PReLU:            
            mask = greaterThanEqual(value, vec4(0.0));
            value = mix(vec4(1.0), vec4(params.activationAlpha), mask);       
        break;
        case ReLU:             
            mask = greaterThanEqual(value, vec4(0.0));
            value = mix(vec4(1.0), vec4(0.0), mask);       
        break;
        case Sigmoid:    
            value *= (1-value);        
        break;
        case Tanh: // shifted tanh [-1,1] to [0,1]    
            value = (tanh(value)/2.0) + 0.5;       
            value = 1 - value * value;
        break;
        default:            
        break;
    }
    return value;
}


vec4 activateFunction(vec4 value){
    bvec4 mask;
    switch (params.activationFunction) {
        case ELU:        
            mask = greaterThanEqual(value, vec4(0.0));
            value = mix(vec4(params.activationAlpha) * (exp(value) - vec4(1.0)), value, mask);
            value = clamp(value, 0.0, 1.0);
        break;
        case LReLU: 
            value = clamp(0.01*value, 0.0, 1.0);
        break;
        case PReLU:
            value = max(params.activationAlpha * value, value);
            value = clamp(value, 0.0, 1.0);
        break;
        case ReLU: 
            value = clamp(value, 0.0, 1.0);            
        break;
        case Sigmoid:
            value = 1.0 / (1.0 + exp(-value));
            value = clamp(value, 0.0, 1.0);
        break;
        case Tanh: // shifted tanh [-1,1] to [0,1]
            value = (tanh(value)/2.0) + 0.5;
        break;
        default:            
        break;
    }
    return value;
}


void main() {    
    // Get the index of the neuron (one workgroup thread per neuron)
    uint index_x = gl_GlobalInvocationID.x;
    uint index_y = gl_GlobalInvocationID.y; 
}