#version 450

/**
 * GLSL backward propagation compute shader for Vulkan, by Dams 
 * Damien Balima (c) CC-BY-NC-SA-4.0 2024
 */

// One workgroup thread per neuron, one local thread per workgroup
layout (local_size_x = 1) in;


// Enum mapping, do not change
const int ELU = 0;
const int LReLU = 1;
const int PReLU = 2;
const int ReLU = 3;
const int Sigmoid = 4;
const int Tanh = 5;


struct Neuron {
    uint index_x;
    uint index_y;
    uint weightsIndex;
    uint neighborsIndex;
    uint neighborsSize;
};

// Shader Storage Buffer Objects (SSBOs)
// will contains current layer neurons
layout (std430, binding = 0)  buffer readonly CurrentLayer {
    Neuron neurons[];
} currentLayer;

// will contains current layer values
layout (std430, binding = 1)  buffer readonly CurrentLayerValues {
    vec4 values[];
} currentLayerValues;

// will contains current layer neighboors errors (multi, indexed)
layout (std430, binding = 2)  buffer readonly CurrentLayerNeighboorsErrors {
    vec4 errors[];
} currentLayerNeighboorsErrors;

// will contains current layer neurons neighboors connections weights (multi, indexed)
layout (std430, binding = 3) buffer readonly  CurrentLayerNeighboorsConnectionWeights {
    vec4 weights[];
} currentLayerNeighboorsConnectionWeights;

// will contains next layer neurons
layout (std430, binding = 4) buffer readonly NextLayer {
    Neuron neurons[];
} nextLayer;

// will contains next layer errors
layout (std430, binding = 5) buffer readonly NextLayerErrors {
    vec4 errors[];
} nextLayerErrors;

// will contains next layer neurons weights (multi, indexed)
layout (std430, binding = 6) buffer readonly NextLayerWeights {
    vec4 weights[];
} nextLayerWeights;

// will contains some parameters
layout (std430, binding = 7) buffer readonly Parameters {
    float error_min;
    float error_max;
    float activationAlpha;
    uint currentLayerSizeX;
    uint currentLayerSizeY;
    uint previousLayerSizeX;
    uint previousLayerSizeY;
    uint nextLayerSizeX;
    uint nextLayerSizeY;
    uint activationFunction;
} params;

// will contains current layer errors (output)
layout (std430, binding = 8)  buffer writeonly CurrentLayerNewErrors {
    vec4 errors[];
} currentLayerNewErrors;


vec4 derivativeFunction(vec4 value){
    bvec4 mask;
    switch (params.activationFunction) {
        case ELU:          
            mask = greaterThanEqual(value, vec4(0.0));
            value = mix(vec4(1.0), params.activationAlpha * exp(value), mask);       
        break;
        case LReLU:    
            value = clamp(value, 0.01, 1.0);         
        break;
        case PReLU:            
            mask = greaterThanEqual(value, vec4(0.0));
            value = mix(vec4(1.0), vec4(params.activationAlpha), mask);       
        break;
        case ReLU:             
            mask = greaterThanEqual(value, vec4(0.0));
            value = mix(vec4(1.0), vec4(0.0), mask);       
        break;
        case Sigmoid:    
            value *= (1-value);        
        break;
        case Tanh: // shifted tanh [-1,1] to [0,1]    
            value = (tanh(value)/2.0) + 0.5;       
            value = 1 - value * value;
        break;
        default:            
        break;
    }
    return value;
}


vec4 computeError(Neuron currentNeuron) {
    vec4 error = vec4(0.0);

    // Add next layer neurons error ponderated with weights for this neuron
      for (uint y = 0; y < params.nextLayerSizeY; ++y) {
        for (uint x = 0; x < params.nextLayerSizeX; ++x) {
            Neuron nextLayerNeuron = nextLayer.neurons[params.nextLayerSizeX * y + x];
            vec4 currentError = nextLayerErrors.errors[params.nextLayerSizeX * y + x];
            vec4 weight = nextLayerWeights.weights[params.currentLayerSizeX * y + x];
            error += currentError * weight;
        }
    }

    // Consider errors of adjacent neurons
    for (uint i = 0; i < currentNeuron.neighborsSize; ++i) {        
        vec4 neighborError = currentLayerNeighboorsErrors.errors[currentNeuron.neighborsIndex + i];
        vec4 connectionWeight = currentLayerNeighboorsConnectionWeights.weights[currentNeuron.neighborsIndex + i];
        error += neighborError * connectionWeight;
    }

    // Use the derivative of the activation function
    vec4 activationDerivative = derivativeFunction(currentLayerValues.values[currentNeuron.index_x * currentNeuron.index_y]);
    vec4 clampedError = clamp(activationDerivative * error, params.error_min, params.error_max);

    return clampedError;
}


void main() {
    // Get the index of the neuron (one workgroup thread per neuron)
    uint index_x = gl_GlobalInvocationID.x;
    uint index_y = gl_GlobalInvocationID.y; 
        
    Neuron currentNeuron = currentLayer.neurons[index_x * params.currentLayerSizeY + index_y];
    
    // Compute the error
    vec4 error = computeError(currentNeuron);

   // Put the results in the output buffer
    currentLayerNewErrors.errors[index_x * params.currentLayerSizeY + index_y] = error;   
}