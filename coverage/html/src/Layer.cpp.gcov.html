<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>LCOV - lcov.info - src/Layer.cpp</title>
  <link rel="stylesheet" type="text/css" href="../gcov.css">
</head>

<body>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="title">LCOV - code coverage report</td></tr>
    <tr><td class="ruler"><img src="../glass.png" width=3 height=3 alt=""></td></tr>

    <tr>
      <td width="100%">
        <table cellpadding=1 border=0 width="100%">
          <tr>
            <td width="10%" class="headerItem">Current view:</td>
            <td width="35%" class="headerValue"><a href="../index.html">top level</a> - <a href="index.html">src</a> - Layer.cpp<span style="font-size: 80%;"> (source / <a href="Layer.cpp.func-sort-c.html">functions</a>)</span></td>
            <td width="5%"></td>
            <td width="15%"></td>
            <td width="10%" class="headerCovTableHead">Hit</td>
            <td width="10%" class="headerCovTableHead">Total</td>
            <td width="15%" class="headerCovTableHead">Coverage</td>
          </tr>
          <tr>
            <td class="headerItem">Test:</td>
            <td class="headerValue">lcov.info</td>
            <td></td>
            <td class="headerItem">Lines:</td>
            <td class="headerCovTableEntry">42</td>
            <td class="headerCovTableEntry">44</td>
            <td class="headerCovTableEntryHi">95.5 %</td>
          </tr>
          <tr>
            <td class="headerItem">Date:</td>
            <td class="headerValue">2024-05-22 21:03:29</td>
            <td></td>
            <td class="headerItem">Functions:</td>
            <td class="headerCovTableEntry">3</td>
            <td class="headerCovTableEntry">3</td>
            <td class="headerCovTableEntryHi">100.0 %</td>
          </tr>
          <tr><td><img src="../glass.png" width=3 height=3 alt=""></td></tr>
        </table>
      </td>
    </tr>

    <tr><td class="ruler"><img src="../glass.png" width=3 height=3 alt=""></td></tr>
  </table>

  <table cellpadding=0 cellspacing=0 border=0>
    <tr>
      <td><br></td>
    </tr>
    <tr>
      <td>
<pre class="sourceHeading">          Line data    Source code</pre>
<pre class="source">
<a name="1"><span class="lineNum">       1 </span>            : #include &quot;Layer.h&quot;</a>
<a name="2"><span class="lineNum">       2 </span>            : #include &quot;VulkanController.h&quot;</a>
<a name="3"><span class="lineNum">       3 </span>            : #include &lt;algorithm&gt;</a>
<a name="4"><span class="lineNum">       4 </span>            : #include &lt;cmath&gt;</a>
<a name="5"><span class="lineNum">       5 </span>            : #include &lt;opencv2/core/hal/interface.h&gt;</a>
<a name="6"><span class="lineNum">       6 </span>            : #include &lt;stdexcept&gt;</a>
<a name="7"><span class="lineNum">       7 </span>            : </a>
<a name="8"><span class="lineNum">       8 </span>            : using namespace sipai;</a>
<a name="9"><span class="lineNum">       9 </span>            : </a>
<a name="10"><span class="lineNum">      10 </span><span class="lineCov">        123 : void Layer::forwardPropagation() {</span></a>
<a name="11"><span class="lineNum">      11 </span><span class="lineCov">        123 :   if (previousLayer == nullptr) {</span></a>
<a name="12"><span class="lineNum">      12 </span><span class="lineNoCov">          0 :     return;</span></a>
<a name="13"><span class="lineNum">      13 </span>            :   }</a>
<a name="14"><span class="lineNum">      14 </span>            : </a>
<a name="15"><span class="lineNum">      15 </span><span class="lineCov">        430 :   for (size_t y = 0; y &lt; neurons.size(); ++y) {</span></a>
<a name="16"><span class="lineNum">      16 </span><span class="lineCov">       1228 :     for (size_t x = 0; x &lt; neurons[y].size(); ++x) {</span></a>
<a name="17"><span class="lineNum">      17 </span><span class="lineCov">        921 :       Neuron &amp;currentNeuron = neurons[y][x];</span></a>
<a name="18"><span class="lineNum">      18 </span>            :       // Compute matrix multiplication between previous layer values</a>
<a name="19"><span class="lineNum">      19 </span>            :       // and current neuron weights</a>
<a name="20"><span class="lineNum">      20 </span><span class="lineCov">        921 :       cv::Mat dotProduct = previousLayer-&gt;values.mul(currentNeuron.weights);</span></a>
<a name="21"><span class="lineNum">      21 </span>            :       // Convert the result matrix to a single value by summing all elements</a>
<a name="22"><span class="lineNum">      22 </span><span class="lineCov">        921 :       cv::Vec4f result = cv::sum(dotProduct);</span></a>
<a name="23"><span class="lineNum">      23 </span>            :       // Update the neuron value using the activation function</a>
<a name="24"><span class="lineNum">      24 </span><span class="lineCov">        921 :       values.at&lt;cv::Vec4f&gt;((int)y, (int)x) = activationFunction(result);</span></a>
<a name="25"><span class="lineNum">      25 </span><span class="lineCov">        921 :     }</span></a>
<a name="26"><span class="lineNum">      26 </span>            :   }</a>
<a name="27"><span class="lineNum">      27 </span>            : }</a>
<a name="28"><span class="lineNum">      28 </span>            : </a>
<a name="29"><span class="lineNum">      29 </span><span class="lineCov">         84 : void Layer::backwardPropagation(const float &amp;error_min,</span></a>
<a name="30"><span class="lineNum">      30 </span>            :                                 const float &amp;error_max) {</a>
<a name="31"><span class="lineNum">      31 </span><span class="lineCov">         84 :   if (nextLayer == nullptr) {</span></a>
<a name="32"><span class="lineNum">      32 </span><span class="lineCov">         42 :     return;</span></a>
<a name="33"><span class="lineNum">      33 </span>            :   }</a>
<a name="34"><span class="lineNum">      34 </span>            : </a>
<a name="35"><span class="lineNum">      35 </span><span class="lineCov">        126 :   for (int y = 0; y &lt; (int)neurons.size(); ++y) {</span></a>
<a name="36"><span class="lineNum">      36 </span><span class="lineCov">        336 :     for (int x = 0; x &lt; (int)neurons[y].size(); ++x) {</span></a>
<a name="37"><span class="lineNum">      37 </span><span class="lineCov">        252 :       Neuron &amp;currentNeuron = neurons[y][x];</span></a>
<a name="38"><span class="lineNum">      38 </span><span class="lineCov">        252 :       cv::Vec4f error(0.0f);</span></a>
<a name="39"><span class="lineNum">      39 </span>            : </a>
<a name="40"><span class="lineNum">      40 </span>            :       // Add next layer neurons error ponderated with weights for this neuron</a>
<a name="41"><span class="lineNum">      41 </span><span class="lineCov">       1008 :       for (const auto &amp;nextLayerNeuronRow : nextLayer-&gt;neurons) {</span></a>
<a name="42"><span class="lineNum">      42 </span><span class="lineCov">       3024 :         for (const auto &amp;nextLayerNeuron : nextLayerNeuronRow) {</span></a>
<a name="43"><span class="lineNum">      43 </span><span class="lineCov">       2268 :           const cv::Vec4f currentError = nextLayer-&gt;errors.at&lt;cv::Vec4f&gt;(</span></a>
<a name="44"><span class="lineNum">      44 </span><span class="lineCov">       2268 :               (int)nextLayerNeuron.index_y, (int)nextLayerNeuron.index_x);</span></a>
<a name="45"><span class="lineNum">      45 </span><span class="lineCov">       2268 :           const cv::Vec4f weight = nextLayerNeuron.weights.at&lt;cv::Vec4f&gt;(y, x);</span></a>
<a name="46"><span class="lineNum">      46 </span><span class="lineCov">       2268 :           error += currentError.mul(weight);</span></a>
<a name="47"><span class="lineNum">      47 </span>            :         }</a>
<a name="48"><span class="lineNum">      48 </span>            :       }</a>
<a name="49"><span class="lineNum">      49 </span>            :       // Consider errors of adjacent neurons</a>
<a name="50"><span class="lineNum">      50 </span><span class="lineCov">        840 :       for (const NeuronConnection &amp;conn : currentNeuron.neighbors) {</span></a>
<a name="51"><span class="lineNum">      51 </span><span class="lineCov">       1176 :         error += conn.weight.mul(errors.at&lt;cv::Vec4f&gt;(</span></a>
<a name="52"><span class="lineNum">      52 </span><span class="lineCov">       1176 :             (int)conn.neuron-&gt;index_y, (int)conn.neuron-&gt;index_x));</span></a>
<a name="53"><span class="lineNum">      53 </span>            :       }</a>
<a name="54"><span class="lineNum">      54 </span>            :       // Use the derivative of the activation function</a>
<a name="55"><span class="lineNum">      55 </span>            :       const cv::Vec4f activationDerivative =</a>
<a name="56"><span class="lineNum">      56 </span><span class="lineCov">        252 :           activationFunctionDerivative(values.at&lt;cv::Vec4f&gt;(y, x));</span></a>
<a name="57"><span class="lineNum">      57 </span>            :       const cv::Vec4f clampedError = Common::clamp4f(</a>
<a name="58"><span class="lineNum">      58 </span><span class="lineCov">        252 :           activationDerivative.mul(error), error_min, error_max);</span></a>
<a name="59"><span class="lineNum">      59 </span>            : </a>
<a name="60"><span class="lineNum">      60 </span><span class="lineCov">        252 :       errors.at&lt;cv::Vec4f&gt;(y, x) = clampedError;</span></a>
<a name="61"><span class="lineNum">      61 </span>            :     }</a>
<a name="62"><span class="lineNum">      62 </span>            :   }</a>
<a name="63"><span class="lineNum">      63 </span>            : }</a>
<a name="64"><span class="lineNum">      64 </span>            : </a>
<a name="65"><span class="lineNum">      65 </span><span class="lineCov">         85 : void Layer::updateWeights(float learningRate) {</span></a>
<a name="66"><span class="lineNum">      66 </span><span class="lineCov">         85 :   if (previousLayer == nullptr) {</span></a>
<a name="67"><span class="lineNum">      67 </span><span class="lineNoCov">          0 :     return;</span></a>
<a name="68"><span class="lineNum">      68 </span>            :   }</a>
<a name="69"><span class="lineNum">      69 </span>            : </a>
<a name="70"><span class="lineNum">      70 </span><span class="lineCov">        298 :   for (int y = 0; y &lt; (int)neurons.size(); ++y) {</span></a>
<a name="71"><span class="lineNum">      71 </span><span class="lineCov">        852 :     for (int x = 0; x &lt; (int)neurons[y].size(); ++x) {</span></a>
<a name="72"><span class="lineNum">      72 </span><span class="lineCov">        639 :       Neuron &amp;neuron = neurons[y][x];</span></a>
<a name="73"><span class="lineNum">      73 </span>            : </a>
<a name="74"><span class="lineNum">      74 </span>            :       // Get the error of current neuron, mult by the learningRate</a>
<a name="75"><span class="lineNum">      75 </span>            :       const cv::Vec4f learningRateError =</a>
<a name="76"><span class="lineNum">      76 </span><span class="lineCov">        639 :           errors.at&lt;cv::Vec4f&gt;(y, x) * cv::Vec4f::all(learningRate);</span></a>
<a name="77"><span class="lineNum">      77 </span>            : </a>
<a name="78"><span class="lineNum">      78 </span>            :       // Create a matrix with dimensions of neuron weights</a>
<a name="79"><span class="lineNum">      79 </span>            :       // and previous learningRateError</a>
<a name="80"><span class="lineNum">      80 </span>            :       cv::Mat learningRateErrorMat(neuron.weights.size(), neuron.weights.type(),</a>
<a name="81"><span class="lineNum">      81 </span><span class="lineCov">        639 :                                    learningRateError);</span></a>
<a name="82"><span class="lineNum">      82 </span>            : </a>
<a name="83"><span class="lineNum">      83 </span>            :       // Update neuron weights that are connections weights with previous layers</a>
<a name="84"><span class="lineNum">      84 </span><span class="lineCov">        639 :       neuron.weights -= previousLayer-&gt;values.mul(learningRateErrorMat);</span></a>
<a name="85"><span class="lineNum">      85 </span>            : </a>
<a name="86"><span class="lineNum">      86 </span>            :       // Update neighbors connections weights</a>
<a name="87"><span class="lineNum">      87 </span><span class="lineCov">       2259 :       for (NeuronConnection &amp;conn : neuron.neighbors) {</span></a>
<a name="88"><span class="lineNum">      88 </span><span class="lineCov">       1620 :         conn.weight -= values</span></a>
<a name="89"><span class="lineNum">      89 </span><span class="lineCov">       1620 :                            .at&lt;cv::Vec4f&gt;((int)conn.neuron-&gt;index_y,</span></a>
<a name="90"><span class="lineNum">      90 </span><span class="lineCov">       1620 :                                           (int)conn.neuron-&gt;index_x)</span></a>
<a name="91"><span class="lineNum">      91 </span><span class="lineCov">       1620 :                            .mul(learningRateError);</span></a>
<a name="92"><span class="lineNum">      92 </span>            :       }</a>
<a name="93"><span class="lineNum">      93 </span><span class="lineCov">        639 :     }</span></a>
<a name="94"><span class="lineNum">      94 </span>            :   }</a>
<a name="95"><span class="lineNum">      95 </span>            : }</a>
</pre>
      </td>
    </tr>
  </table>
  <br>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="ruler"><img src="../glass.png" width=3 height=3 alt=""></td></tr>
    <tr><td class="versionInfo">Generated by: <a href="https://github.com/linux-test-project/lcov" target="_parent">LCOV version 1.16</a></td></tr>
  </table>
  <br>

</body>
</html>
